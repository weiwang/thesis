\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces \em Measure of fit (estimated prediction error) for all response outcomes in the 2006 Cooperative Congressional Election Survey. Outcomes are ordered by the lower bound (in-sample loss of the saturated model). The no pooling model gives a bad fit. Partial pooling does best but in most cases is almost indistinguishable from complete pooling under the cross-validation criterion.}}{14}{figure.2.1}
\contentsline {figure}{\numberline {2.2}{\ignorespaces \em Left panel: Cell proportion estimates for three models of vote intention. Each line is a state. The partial pooling model pools so much that it is indistinguishable from complete pooling. Right panel: The same estimates for the 10 most populous states. Still, partial pooling estimates are similar to complete pooling estimates.}}{16}{figure.2.2}
\contentsline {figure}{\numberline {2.3}{\ignorespaces \em Estimated prediction error of all response outcomes for augmented data sets. From top to bottom, the data sets have 2, 3, and 4 times as many data points as the original data set. The outcomes are ordered by the in-sample predictive loss. As sample size grows, complete pooling gradually gets worse and no pooling gets better.}}{18}{figure.2.3}
\contentsline {figure}{\numberline {2.4}{\ignorespaces \em Prediction error of the three models as sample size grows. The outcome under consideration is partisan vote preference in the upcoming congressional election. By this criterion, partial pooling and complete pooling perform similarly until sample size exceeds 50,000.}}{19}{figure.2.4}
\contentsline {figure}{\numberline {2.5}{\ignorespaces \em Measure of fit (prediction error) for all outcomes, ordered by in-sample training loss. The data set is simulated from real data set, and has the same sample size in total as the real data set, but keeping all demographic-geographic cells balanced. In this case, complete pooling model has much higher prediction errors than no pooling and partial pooling. Partial pooling is slightly but consistently better than no pooling. In particular, no pooling model has huge prediction error for outcomes that have smaller in-sample training loss.}}{21}{figure.2.5}
\contentsline {figure}{\numberline {2.6}{\ignorespaces \em Prediction error of the three models as sample size grows under the simulated balanced data set. The outcome under consideration is the vote for the Republican candidate in the U.S House of Representatives. Partial pooling has the lowest prediction error when sample size is under 70,000.}}{22}{figure.2.6}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces A comparison of the demographic, partisan, and 2008 vote distribution in the Xbox dataset and the 2012 electorate (as measured by adjusted exit polls). The sex and age distributions, as one might expect, exhibit considerable differences.}}{31}{figure.3.1}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Daily (unadjusted) Xbox estimates of two-party Obama support during the 45 days leading up to the 2012 presidential election, which suggest a landslide victory for Mitt Romney. The dotted blue line indicates a consensus average of traditional polls (the daily aggregated polling results from Pollster.com), the horizontal dashed line at 52\% indicates the actual two-party vote share obtained by Barack Obama, and the vertical dotted lines give the dates of the three presidential debates.}}{32}{figure.3.2}
\contentsline {figure}{\numberline {3.3}{\ignorespaces National MRP-adjusted voter intent of two-party Obama support over the 45-day period and the associated 95\% confidence bands. The horizontal dashed line indicates the actual two-party Obama vote share. The three vertical dotted lines indicate the presidential debates. Compared with the raw responses in Figure \ref {fig:raw_responses}, the MRP-adjusted voter intent is much more reasonable, and voter intent in the last few days is very close to the actual outcome. For comparison, the daily aggregated polling results from Pollster.com, shown as the blue dotted line, are further away from the actual vote share than the estimates generated from the Xbox data in the last few days.}}{39}{figure.3.3}
\contentsline {figure}{\numberline {3.4}{\ignorespaces MRP-adjusted daily voter intent for the 12 states with the most electoral votes, and the associated 95\% confidence bands. The horizontal dashed lines in each panel give the actual two-party Obama vote shares in that state. The mean and median absolute errors of the last day voter intent across the 51 Electoral College races are 2.5 and 1.8 percentage points, respectively. The state-by-state daily aggregated polling results from Pollster.com, given in the dotted blue lines, are broadly consistent with the estimates from the Xbox data.}}{41}{figure.3.4}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Comparison of two-party Obama vote share for various demographic subgroups, as estimated from the 2012 national exit poll and from the Xbox data on the day before the election. }}{42}{figure.3.5}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Two-party Obama support as estimated from the 2012 national exit poll and from the Xbox data on the day before the election, for various two-way interaction demographic subgroups (e.g., 65+ year-old women). The sizes of the dots are proportional to the population sizes of the corresponding subgroups. Subgroups within the same two-way interaction category (e.g., age by sex) have the same color.}}{43}{figure.3.6}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Differences between the Xbox MRP-adjusted estimates and the exit poll estimates for the 30 largest two-dimensional demographic subgroups, ordered by the difference. Positive values indicate the Xbox estimate is larger than the corresponding exit poll estimate. Among these 30 subgroups, the median and mean absolute differences are 1.9 and 2.2 percentage points, respectively.}}{45}{figure.3.7}
\contentsline {figure}{\numberline {3.8}{\ignorespaces Projected Obama share of the two-party vote on election day for each of the 12 states with the most electoral votes, and associated 95\% confidence bands. Compared to the MRP-adjusted voter intent in Figure \ref {fig:state_snap}, the projected two-party Obama support is more stable, and the North Carolina race switches direction after applying the calibration model. Additionally, the confidence bands become much wider and give more reasonable state-by-state probabilities of Obama victories.}}{50}{figure.3.8}
\contentsline {figure}{\numberline {3.9}{\ignorespaces Comparison between the probability of Obama winning the 12 largest Electoral College races based on Xbox data and on prediction market data. The prediction market data are the average of the raw Betfair and Intrade prices from winner-take-all markets. The three vertical lines represent the dates of three presidential debates. The shaded halves indicate the direction that race went.}}{51}{figure.3.9}
\contentsline {figure}{\numberline {3.10}{\ignorespaces Daily projections of Obama electoral votes in the 45-day period leading up to the 2012 election and associated 95\% confidence bands. The solid line represents the median of the daily distribution. The horizontal dashed line represents the actual electoral votes, 332, that Obama captured in 2012 election. Three vertical dotted lines indicate the dates of three presidential debates.}}{52}{figure.3.10}
\contentsline {figure}{\numberline {3.11}{\ignorespaces Projected distribution of electoral votes for Obama one day before the election. The green vertical dotted line represents 269, the minimum number of electoral votes that Obama needs for a tie. The blue vertical dashed line gives 332, the actual number of electoral votes captured by Obama. The estimated likelihood of Obama winning the electoral vote is 88\%.}}{53}{figure.3.11}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Above: Counterfactual scaled math scores with one standard deviation if a minority female pupil receiving free lunch were assigned to 8 different schools and 3 different treatments. Below: Counterfactual scaled math scores with one standard deviation if a minority male pupil receiving free lunch were assigned to 8 different schools and 3 different treatments. Schools are ordered from left to right by the proportions of student receiving free lunch.}}{71}{figure.4.1}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Above: Counterfactual scaled math scores with one standard deviation if a minority female pupil not receiving free lunch were assigned to 8 different schools and 3 different treatments. Below: Counterfactual scaled math scores with one standard deviation if a minority male pupil not receiving free lunch were assigned to 8 different schools and 3 different treatments. Schools are ordered from left to right by the proportions of student receiving free lunch.}}{72}{figure.4.2}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Above: Counterfactual scaled math scores with one standard deviation if a white female pupil receiving free lunch were assigned to 8 different schools and 3 different treatments. Below: Counterfactual scaled math scores with one standard deviation if a white male pupil receiving free lunch were assigned to 8 different schools and 3 different treatments. Schools are ordered from left to right by the proportions of student receiving free lunch.}}{73}{figure.4.3}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Above: Counterfactual scaled math scores with one standard deviation if a white female pupil not receiving free lunch were assigned to 8 different schools and 3 different treatments. Below: Counterfactual scaled math scores with one standard deviation if a white male pupil not receiving free lunch were assigned to 8 different schools and 3 different treatments. Schools are ordered from left to right by the proportions of student receiving free lunch.}}{74}{figure.4.4}
